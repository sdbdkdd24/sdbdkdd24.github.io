<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="theme-color" content="#33474d">
    <title>The Fourth International Workshop on Smart Data for Blockchain and Distributed Ledger (SDBD’24)</title>
    <link rel="stylesheet" href="/css/style.css"/>

    <link rel="alternate" href="/atom.xml"
          title="The Fourth International Workshop on Smart Data for Blockchain and Distributed Ledger (SDBD’24)"
          type="application/atom+xml">

    <meta name="generator" content="Hexo 5.4.0">
</head>

<body>
<div class="header__nav__container">
    <nav class="header__nav">

        <a href="/" class="header__link">Home</a>

        <a href="/Call-For-Papers" class="header__link">Call For Papers</a>
        <a href="/Committee" class="header__link">Committee</a>
        <a href="/Keynotes" class="header__link">Keynotes</a>     
        <a href="/Accepted-Papers" class="header__link header__link__active">Accepted Papers</a>
        <a href="/Schedule" class="header__link">Schedule</a>
        <a target="_blank" rel="noopener" href="https://kdd2024.kdd.org/" class="header__link">KDD 2024</a>
    </nav>
</div>
<header class="header">
    <h1 class="header__title">The Fourth International Workshop on Smart Data for Blockchain and Distributed Ledger
        (SDBD’24)</h1>
    <h2 class="header__subtitle">Co-located with <a target="_blank" rel="noopener" href="https://kdd2024.kdd.org/"
                                                    class="header__link_2">ACM SIGKDD 2024</a>, August 26th, Barcelona,
        Spain</h2>
</header>

<main>
    <article>
        <h1></h1>

        <h3 id="Organizers"><a href="#Organizers" class="headerlink" title="Organizers"></a>Organizers</h3>
        <p>To Be Anounced.</p>


    </article>

</main>

<table>
        <tr>
            <td>
                <h2 style="font-size: 20px">Practical Fairness: An Evaluation of Bias Mitigation Strategies for NLP Applications</h2> 
                <strong>Bryce E King, Beverly Thompson</strong> 
<!--                 <a class="btn btn-red" href="camera_ready/multiple.pdf">PDF</a>  -->
                <br>
                <u>Abstract</u>: As the use of algorithmic decision-making becomes more widely adopted, there is a growing need for practical strategies to mitigate bias in automated systems, particularly in natural language processing. Due to a lack of standardization, comprehensive evaluation metrics, and real-world evaluation, comparing different mitigation strategies is challenging. In this work, we demonstrate the presence of gender bias when using the large language model (LLM) RoBERTa to classify occupation from text samples similar to LinkedIn bios. We then provide a holistic evaluation of ten bias mitigation strategies applied to a common problem, providing insights into their effectiveness and trade-offs under different constraints. Based on this analysis, we offer guidance for companies on selecting the most suitable strategy for a given circumstance with consideration to computational constraints, metric priorities, and dataset characteristics. This work contributes a consistent assessment of the efficacy and trade-offs of common bias mitigation techniques that could be used in real-world applications as well as a point of comparison for future methodologies.
            </td>
        </tr>
<table>
    


    

<footer class="footer">
    <div class="footer-content">
        <div class="footer-credit">
            <span>Copyright © <a target="_blank" rel="noopener" href="https://kdd2024.kdd.org/">SIGKDD</a></span>
            2024</span>
        </div>

    </div>


</footer>


</body>

</html>
